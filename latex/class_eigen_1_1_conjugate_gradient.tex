\hypertarget{class_eigen_1_1_conjugate_gradient}{}\doxysection{Eigen\+::Conjugate\+Gradient$<$ \+\_\+\+Matrix\+Type, \+\_\+\+Up\+Lo, \+\_\+\+Preconditioner $>$ Class Template Reference}
\label{class_eigen_1_1_conjugate_gradient}\index{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$@{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$}}


A conjugate gradient solver for sparse (or dense) self-\/adjoint problems.  




{\ttfamily \#include $<$Conjugate\+Gradient.\+h$>$}

\doxysubsection*{Public Types}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ae7391a5954fb41bef93331fb73cfd58c}\label{class_eigen_1_1_conjugate_gradient_ae7391a5954fb41bef93331fb73cfd58c}} 
enum \{ {\bfseries Up\+Lo} = \+\_\+\+Up\+Lo
 \}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ac7e663c3436a92b0c2f45b288fbc1bb9}\label{class_eigen_1_1_conjugate_gradient_ac7e663c3436a92b0c2f45b288fbc1bb9}} 
typedef \+\_\+\+Matrix\+Type {\bfseries Matrix\+Type}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a8c5a83c590bec382e23713092bfeec3f}\label{class_eigen_1_1_conjugate_gradient_a8c5a83c590bec382e23713092bfeec3f}} 
typedef Matrix\+Type\+::\+Scalar {\bfseries Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_aa29f85be5f03e532742c148d00cd56b8}\label{class_eigen_1_1_conjugate_gradient_aa29f85be5f03e532742c148d00cd56b8}} 
typedef Matrix\+Type\+::\+Real\+Scalar {\bfseries Real\+Scalar}
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a3d4ee165efe6de3647f9a1bc8074b8f0}\label{class_eigen_1_1_conjugate_gradient_a3d4ee165efe6de3647f9a1bc8074b8f0}} 
typedef \+\_\+\+Preconditioner {\bfseries Preconditioner}
\end{DoxyCompactItemize}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_a92a9656ca9fa4da240194f89229255eb}{Conjugate\+Gradient}} ()
\item 
{\footnotesize template$<$typename Matrix\+Derived $>$ }\\\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient_ac10f778fcd137eca1f6057c8ddd3d644}{Conjugate\+Gradient}} (const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&\mbox{\hyperlink{class_eigen_1_1_matrix}{A}})
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a06dadd6b4282026f340202d987ecd23f}\label{class_eigen_1_1_conjugate_gradient_a06dadd6b4282026f340202d987ecd23f}} 
{\footnotesize template$<$typename Rhs , typename Dest $>$ }\\void {\bfseries \+\_\+solve\+\_\+with\+\_\+guess\+\_\+impl} (const Rhs \&b, Dest \&x) const
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a29cf39cbb200b90db87c83fea233478c}\label{class_eigen_1_1_conjugate_gradient_a29cf39cbb200b90db87c83fea233478c}} 
{\footnotesize template$<$typename Rhs , typename Dest $>$ }\\void {\bfseries \+\_\+solve\+\_\+impl} (const \mbox{\hyperlink{class_eigen_1_1_matrix_base}{Matrix\+Base}}$<$ Rhs $>$ \&b, Dest \&x) const
\item 
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a7c2a35dde0ddb891b4030143ed286743}\label{class_eigen_1_1_conjugate_gradient_a7c2a35dde0ddb891b4030143ed286743}} 
{\footnotesize template$<$typename Rhs , typename Dest\+Derived $>$ }\\void {\bfseries \+\_\+solve\+\_\+impl} (const Rhs \&b, \mbox{\hyperlink{class_eigen_1_1_sparse_matrix_base}{Sparse\+Matrix\+Base}}$<$ Dest\+Derived $>$ \&a\+Dest) const
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\subsubsection*{template$<$typename \+\_\+\+Matrix\+Type, int \+\_\+\+Up\+Lo, typename \+\_\+\+Preconditioner$>$\newline
class Eigen\+::\+Conjugate\+Gradient$<$ \+\_\+\+Matrix\+Type, \+\_\+\+Up\+Lo, \+\_\+\+Preconditioner $>$}

A conjugate gradient solver for sparse (or dense) self-\/adjoint problems. 

This class allows to solve for A.\+x = b linear problems using an iterative conjugate gradient algorithm. The matrix A must be selfadjoint. The matrix A and the vectors x and b can be either dense or sparse.


\begin{DoxyTemplParams}{Template Parameters}
{\em \+\_\+\+Matrix\+Type} & the type of the matrix A, can be a dense or a sparse matrix. \\
\hline
{\em \+\_\+\+Up\+Lo} & the triangular part that will be used for the computations. It can be Lower, {\ttfamily Upper}, or {\ttfamily Lower$\vert$\+Upper} in which the full matrix entries will be considered. Default is {\ttfamily Lower}, best performance is {\ttfamily Lower$\vert$\+Upper}. \\
\hline
{\em \+\_\+\+Preconditioner} & the type of the preconditioner. Default is \mbox{\hyperlink{class_eigen_1_1_diagonal_preconditioner}{Diagonal\+Preconditioner}}\\
\hline
\end{DoxyTemplParams}
\textbackslash{}implsparsesolverconcept

The maximal number of iterations and tolerance value can be controlled via the set\+Max\+Iterations() and set\+Tolerance() methods. The defaults are the size of the problem for the maximal number of iterations and Num\+Traits$<$\+Scalar$>$\+::epsilon() for the tolerance.

The tolerance corresponds to the relative residual error\+: $\vert$\+Ax-\/b$\vert$/$\vert$b$\vert$

{\bfseries{Performance\+:}} Even though the default value of {\ttfamily \+\_\+\+Up\+Lo} is {\ttfamily Lower}, significantly higher performance is achieved when using a complete matrix and {\bfseries{Lower$\vert$\+Upper}} as the {\itshape \+\_\+\+Up\+Lo} template parameter. Moreover, in this case multi-\/threading can be exploited if the user code is compiled with Open\+MP enabled. See \mbox{\hyperlink{TopicMultiThreading}{Eigen and multi-\/threading}} for details.

This class can be used as the direct solver classes. Here is a typical usage example\+: 
\begin{DoxyCode}{0}
\DoxyCodeLine{\textcolor{keywordtype}{int} n = 10000;}
\DoxyCodeLine{VectorXd x(n), b(n);}
\DoxyCodeLine{SparseMatrix<double> A(n,n);}
\DoxyCodeLine{\textcolor{comment}{// fill A and b}}
\DoxyCodeLine{ConjugateGradient<SparseMatrix<double>, \mbox{\hyperlink{group__enums_gga39e3366ff5554d731e7dc8bb642f83cdaf581029282d421eee5aae14238c6f749}{Lower}}|\mbox{\hyperlink{group__enums_gga39e3366ff5554d731e7dc8bb642f83cdafca2ccebb604f171656deb53e8c083c1}{Upper}}> cg;}
\DoxyCodeLine{cg.compute(A);}
\DoxyCodeLine{x = cg.solve(b);}
\DoxyCodeLine{std::cout << \textcolor{stringliteral}{"\#iterations:     "} << cg.iterations() << std::endl;}
\DoxyCodeLine{std::cout << \textcolor{stringliteral}{"estimated error: "} << cg.error()      << std::endl;}
\DoxyCodeLine{\textcolor{comment}{// update b, and solve again}}
\DoxyCodeLine{x = cg.solve(b);}
\end{DoxyCode}


By default the iterations start with x=0 as an initial guess of the solution. One can control the start using the solve\+With\+Guess() method.

\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} can also be used in a matrix-\/free context, see the following \mbox{\hyperlink{group___matrixfree_solver_example}{example }}.

\begin{DoxySeeAlso}{See also}
class \mbox{\hyperlink{class_eigen_1_1_least_squares_conjugate_gradient}{Least\+Squares\+Conjugate\+Gradient}}, class \mbox{\hyperlink{class_eigen_1_1_simplicial_cholesky}{Simplicial\+Cholesky}}, \mbox{\hyperlink{class_eigen_1_1_diagonal_preconditioner}{Diagonal\+Preconditioner}}, \mbox{\hyperlink{class_eigen_1_1_identity_preconditioner}{Identity\+Preconditioner}} 
\end{DoxySeeAlso}


\doxysubsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_a92a9656ca9fa4da240194f89229255eb}\label{class_eigen_1_1_conjugate_gradient_a92a9656ca9fa4da240194f89229255eb}} 
\index{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$@{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$@{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename \+\_\+\+Matrix\+Type , int \+\_\+\+Up\+Lo, typename \+\_\+\+Preconditioner $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ \+\_\+\+Matrix\+Type, \+\_\+\+Up\+Lo, \+\_\+\+Preconditioner $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}}

Default constructor. \mbox{\Hypertarget{class_eigen_1_1_conjugate_gradient_ac10f778fcd137eca1f6057c8ddd3d644}\label{class_eigen_1_1_conjugate_gradient_ac10f778fcd137eca1f6057c8ddd3d644}} 
\index{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$@{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$}!ConjugateGradient@{ConjugateGradient}}
\index{ConjugateGradient@{ConjugateGradient}!Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$@{Eigen::ConjugateGradient$<$ \_MatrixType, \_UpLo, \_Preconditioner $>$}}
\doxysubsubsection{\texorpdfstring{ConjugateGradient()}{ConjugateGradient()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename \+\_\+\+Matrix\+Type , int \+\_\+\+Up\+Lo, typename \+\_\+\+Preconditioner $>$ \\
template$<$typename Matrix\+Derived $>$ \\
\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Eigen\+::\+Conjugate\+Gradient}}$<$ \+\_\+\+Matrix\+Type, \+\_\+\+Up\+Lo, \+\_\+\+Preconditioner $>$\+::\mbox{\hyperlink{class_eigen_1_1_conjugate_gradient}{Conjugate\+Gradient}} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{struct_eigen_1_1_eigen_base}{Eigen\+Base}}$<$ Matrix\+Derived $>$ \&}]{A }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}

Initialize the solver with matrix {\itshape A} for further {\ttfamily Ax=b} solving.

This constructor is a shortcut for the default constructor followed by a call to compute().

\begin{DoxyWarning}{Warning}
this class stores a reference to the matrix A as well as some precomputed values that depend on it. Therefore, if {\itshape A} is changed this class becomes invalid. Call compute() to update it with the new matrix A, or modify a copy of A. 
\end{DoxyWarning}


The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
/\+Users/rileyannereid/\+Pycharm\+Projects/\+Stanford\+\_\+\+Raytracer/damping/lib/eigen/\+Eigen/src/\+Iterative\+Linear\+Solvers/Conjugate\+Gradient.\+h\end{DoxyCompactItemize}
